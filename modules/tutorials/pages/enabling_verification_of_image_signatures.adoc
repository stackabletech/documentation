= Enabling verification of image signatures

Image signing is a security measure that helps ensure the authenticity and integrity of container images. Starting with SDP 23.11, all our images are signed https://docs.sigstore.dev/cosign/openid_signing/["keyless"]. By verifying these signatures, cluster administrators can ensure that the images pulled from Stackable's container registry are authentic and have not been tampered with.
Since Kubernetes does not have native support for verifying image signatures yet, we will use Sigstore's https://docs.sigstore.dev/policy-controller/overview/[Policy Controller] in this tutorial.

IMPORTANT: Releases prior to SDP 23.11 do not have signed images. If you are using an older release and enforce image signature verification, Pods with Stackable images will be prevented from starting.

== Installing the Policy Controller
The Policy Controller can be easily installed via Helm:

[source,bash]
----
helm repo add sigstore https://sigstore.github.io/helm-charts
helm repo update
helm install policy-controller sigstore/policy-controller
----

The default settings might not be appropriate for your environment, please refer to the https://artifacthub.io/packages/helm/sigstore/policy-controller[configurable values for the Helm chart] for more information.


== Creating a policy to verify image signatures

Now that the Policy Controller is installed, we can create a policy that verifies that all images provided by Stackable are signed by Stackable's CI pipeline (Github Actions):

[source,yaml]
include::example$verify-signatures/stackable-image-policy.yaml[]

Apply this policy to the cluster by saving it as `stackable-image-policy.yaml` and running:
[source,bash]
----
kubectl apply -f stackable-image-policy.yaml
----

If you used the default values for the Helm chart, policies will only be applied to namespaces labeled with `policy.sigstore.dev/include: "true"`.
Add a label for the namespace where you deployed SDP:
[source,bash]
----
kubectl label namespace stackable policy.sigstore.dev/include=true
----

The Policy Controller checks all newly created Pods in this namespace that run any image matching `+++**+++.stackable.tech/+++**+++` (this matches images provided by Stackable) and ensures that these images have been signed by a Stackable Github Action. If the signature of an image is invalid or missing, the policy will deny the pod creation.
For a more detailed explanation of the policy options, please refer to the https://docs.sigstore.dev/policy-controller/overview/#configuring-image-patterns[Sigstore documentation].
If the `subjectRegExp` field in the policy is changed to something like `https://github.com/test/.+`, the policy will deny the creation of pods with Stackable images because the identity of the subject that signed the image (a Stackable Github Action Workflow) will no longer match the expression specified in the policy.

== Verifying image signatures in an air-gapped environment

// intro
As mentioned before, our images and Helm charts for SDP are signed keyless. Keyless signing is more complex than "classic" signing with a private and public key, but brings several https://www.chainguard.dev/unchained/benefits-of-keyless-software-signing[benefits]. It's also in line with Kubernetes, https://kubernetes.io/docs/tasks/administer-cluster/verify-signed-artifacts/[which uses keyless signing as well].

=== The general setup

The Policy Controller needs an up-to-date version of the root of trust, this is distributed as a collection of files and in an online setting it is automatically fetched from the https://tuf-repo-cdn.sigstore.dev/[Sigstore TUF Repo CDN].

NOTE: https://theupdateframework.io/[The Update Framework (TUF)] is the mechanism used by the Policy Controller to update the root of trust.

In an air-gapped environment, the CDN is not available, and so instead you have to provide the root of trust files yourself.
There are multiple ways to do this, and you should pick the way that works best for your air-gapped environment.

The files hosted in the CDN are available also on https://github.com/sigstore/root-signing/tree/main/repository/repository[GitHub].
This is the source where you need to get the files.
Then there are two ways to provide these files to the Policy Controller inside of your air-gapped Kubernetes.
Either by hosting them with a HTTP server that is reachable by the Policy Controller, or by zipping the files, serializing them and putting them directly into a custom resource.
For both options we refer to the Sigstore documentation: https://docs.sigstore.dev/policy-controller/overview/#configuring-trustroot-for-custom-tuf-root[configuring a mirror] or https://docs.sigstore.dev/policy-controller/overview/#configuring-trustroot-for-custom-tuf-repository[serializing the files into a custom resource].

Both options yield you a TrustRoot custom resource which you then need to configure in your ClusterImagePolicy.
This is done via the `trustRootRef` attribute, as shown https://docs.sigstore.dev/policy-controller/overview/#configuring-verification-against-different-sigstore-instances[in the Policy Controller's documentation].

=== Updating

The problem for air-gapped environments is that expiration of keys is built into TUF.
That means, to verify image signatures continuously, the Policy Controller needs an up-to-date version of the root of trust.

Depending on which way you are providing the root of trust (mirror or direct files), you need to update that accordingly.
If your cluster has access to for example a bastion host that in turn has limited internet access, configuring a mirror might be the easier way to go for you.
You might even be able to simply configure a reverse proxy to https://tuf-repo-cdn.sigstore.dev/ to avoid manually updating files periodically.

If your setup is completely air-gapped, you will have to do periodic manual updates of the files that you deployed earlier.
It is not clear how often the root of trust needs to be updated (TODO: research if we can find out more)

Either refresh your mirror or periodically supply the files directly via other methods into your airgapped system.

The Policy Controller does not need to be restarted. (TODO verify)

== Further reading

...

=== Background: How it usually works online with Fulcio

Describing the whole flow with all the components is out of scope for this documentation, so we will try to provide a summary of the most important parts instead: +
To verify that an image has been signed by Stackable, customers check that the image has a valid signature and that this signature was created by Stackable's CI (Github Actions). More specifically, they check that the identity of the signer is one of Stackable's Github Actions workflows and that this identity has been confirmed by a trusted authority (Github in that case). The role of the Sigstore project https://github.com/sigstore/fulcio[Fulcio] is to issue a certificate for exactly that: +
"This Fulcio instance confirms that this signature was created by `https://github.com/stackabletech/docker-images/.github/workflows/release.yml@refs/tags/23.11.0` and `https://token.actions.githubusercontent.com` confirmed that identity".

By default, the public Fulcio instance hosted by Sigstore is used for this, which is what we do at Stackable as well.

That means customers wanting to verify these image signatures need to trust the Fulcio instance, which issues the certificates that attest the identity of the signer. The root of trust for Sigstore components like the public Fulcio instance is distributed by a framework called https://docs.sigstore.dev/signing/overview/#root-of-trust[The Update Framework (TUF)]. Thankfully, the whole initialization of the root of trust via TUF is handled by the Policy Controller.
