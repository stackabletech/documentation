= Overview

To analyze the data we now have in Druid, we will connect Superset to our Druid instance, and read and visualize the data in Superset.

== Deploy the Stackable Superset operator

As before, we need to install the operator:

[source, bash]
helm install superset-operator stackable-stable/superset-operator

== Deploy Postgresql (for Superset metadata)

Superset requires an SQL database to run. We will install a dedicated database for Superset: as before, we will use the Bitnami PostgreSQL helm chart to deploy a PostgreSQL instance.

[source]
helm install superset-postgresql postgresql \
    --repo https://charts.bitnami.com/bitnami \
    --set auth.username=superset \
    --set auth.password=superset \
    --set auth.database=superset \
    --version 11.0.0

Next we create a secret with the database credentials in it, in the key `connections.sqlalchemyDatabaseUri`. The secret also contains the information of the initial admin user:

[source]
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: simple-superset-credentials
type: Opaque
stringData:
  adminUser.username: admin
  adminUser.firstname: Superset
  adminUser.lastname: Admin
  adminUser.email: admin@superset.com
  adminUser.password: admin
  connections.secretKey: thisISaSECRET_1234
  connections.sqlalchemyDatabaseUri: postgresql://superset:superset@superset-postgresql.default.svc.cluster.local/superset
EOF

== Deploy the Superset cluster

Now we can deploy Superset:

[source]
cat <<EOF | kubectl apply -f -
apiVersion: superset.stackable.tech/v1alpha1
kind: SupersetCluster
metadata:
  name: simple-superset
spec:
  version: 1.4.1  # <1>
  statsdExporterVersion: v0.22.4
  credentialsSecret: simple-superset-credentials  # <2>
  nodes:
    roleGroups:
      default:
        config:
EOF

<1> This is the version of Superset we want to use. You can find our supported Superset version in the https://docs.stackable.tech/superset/index.html#_supported_versions[Superset documentation].
<2> Here we reference our secret we created earlier.

On the first deployment of the Superset cluster, the operator will also initialize the database. Once the database is initialized, you can connect to the cluster.

You can verify that the database is up and running with this command:

[source]
kubectl get statefulset superset-postgresql -o \
jsonpath='{.status.readyReplicas}'

It should return `1`.

==== Setup port-forwarding for the Superset UI

You can also connect to the Superset UI:

[source]
kubectl port-forward service/simple-superset-external 8088

And now point your browser to `http://localhost:8088/` and you will see the login screen of Superset:

image::docathon-2022-01/superset-login.png[Login]

Here you can login with your admin user; if you haven’t chosen different credentials, the ones used above are username `admin` and password `admin`.

Now that we have Druid and Superset running, it is time to connect the two. The Superset operator can take care of that. We deploy a dedicated `DruidConnection` resource:

[source]
cat <<EOF | kubectl apply -f -
apiVersion: superset.stackable.tech/v1alpha1
kind: DruidConnection
metadata:
  name: superset-druid-connection
spec:
  superset:
    name: simple-superset  # <1>
    namespace: default
  druid:
    name: druid-nytaxidata  # <2>
    namespace: default
EOF

<1> The name of our Superset cluster
<2> The name of the Druid cluster

The operator will create a job that adds this connection to the Superset cluster.

We can now find our Druid cluster as a data source in Superset. In the menu, under `Data` > `Databases` you should see the Druid cluster:

image::docathon-2022-01/superset-databases.png[Databases]

**N.B. Troubleshooting**: If you do not see your Druid instance, check the status on the `DruidConnection` you deployed (`superset-druid-connection`), it should be `Ready`.

== Querying Druid Data from Superset

Now, to read the data from our Druid dataset, we need to create a dataset in Superset too, this is done under “Data” > “Datasets”:

image::docathon-2022-01/superset-dataset.png[Dataset]

The data can be queried in `SQL Lab` -> `SQL Editor`:

image::docathon-2022-01/superset-query.png[SQL Editor]

== Data analysis and Dashboards

Once the dataset has been defined, it can be used to create a chart:

image::docathon-2022-01/superset-chart.png[Chart]

As an example, we create a simple line chart. Applying these settings, we can see from the chart (and the average tip amount) that passengers are more generous towards the end of the month:

==== Settings

NOTE: the range has been set so that it matches the filter originally applied in the Nifi template.

|===
|Chart Setting |Value

|Time column
|`__time`

|Time range
|`2020-05-01 ≤ col < 2020-06-01`

|Metrics
|`AVG(tip_amount)`

|X axis title
|`May 2020`

|X axis title bottom margin
|`30`

|Y axis title
|`USD`

|Y axis title margin
|`30`

|X axis time format
|`%a`
|===


image::docathon-2022-01/superset-chart2.png[Chart2]

Finally, you can create a dashboard with this chart:

image::docathon-2022-01/superset-dashboard.png[Dashboard]