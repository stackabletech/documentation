= Logging and Log Aggregation Architecture
Felix Hennig <felix.hennig@stackable.tech>
v0.1, 2022-10-26
:status: [draft]

* Status: {status}
* Deciders:
** Felix Hennig
** Lars Francke
** Malte Sander
** Razvan Mihai
** Sebastian Bernauer
** Siegfried Weber
** Sönke Liebau
** Teo Klestrup Röijezon
* Date: 2022-10-26

Technical Story: https://github.com/stackabletech/issues/issues/202, https://github.com/stackabletech/issues/issues/261

== Context and Problem Statement

// Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.

As a user of the platform, I have poor visibility into what is happening in different components of the platform, as well as how components influence each other, especially the operator and the product clusters it manages.

Logs usually give this insight. Currently, every pod logs to stdout with a certain default log format. For log configuration we support setting a custom log configuration file in some products.

Logs are **not persisted**, a crashed pod is difficult to investigate. Logs are **not aggregated**, investigating issues that involve multiple pods is difficult. Log **configuration is difficult** or impossible.

== Decision Drivers

* **identical configuration** - All product logs should be configurable in the same way, no matter their underlying logging framework (log4j, logback, Python logging, etc.). Every product should have a logging section in its CRD.
* **easily configured sinks** - A log sink (i.e. elasticsearch) should only be configured in a single place for the whole platform (not in every product instance).
* **Support plaintext logs on stdout** - It is a Kubernetes convention to log in plaintext to stdout. This should be kept, as it is a useful tool for interactive debugging.
* **custom overrides** - The log format, aggregator and sink should be substitutable by the user.
* **transport security** - Logs should transmitted with encryption/TLS.

=== Assumptions

* **RegEx parsing is error prone** - Parsing pure string log output to get structure (time, module, log level, message, ...) is prone to errors. Especially for multi-line messages like stacktraces. The design should use structured log ouput whenever possible.

=== Constraints

* **Multiple files** - Some products like HDFS _need_ to log to (multiple) files, so parsing just stdout is not sufficient; we need to parse files.

== Decision

We decided to use https://vector.dev/[Vector] as an aggregator. It looked good, no other options were evaluated.

We chose to provide **plaintext logs on stdout** and **structured logs on file**. For the architecture, we chose to deploy the agent as a **sidecar** and **use an aggregator**. We chose to provide **OpenSearch** as a default Sink for logs.

Find detailed considerations below.

=== Log Aggregation Framework: Vector

https://vector.dev/[Vector] has been picked without comparison to other existing choices. Some googling shows https://medium.com/ibm-cloud/log-collectors-performance-benchmarking-8c5218a08fea[Vector has better performance than fluentd], the biggest name in this space. Vector is also open source and written in Rust: https://github.com/vectordotdev/vector[GitHub].

=== Log Retrieval Strategy

We want to parse logs out of structured log entries and also keep the stdout log as plaintext. Also, some products require reading log files instead of stdout. Which means **we opt to read logs from files for every product** and **parse structured log entries**.

=== Log Aggregation Architecture

**Agent role** - Vector offers multiple https://vector.dev/docs/setup/deployment/roles/#agent[roles] in which it can run. The DaemonSet is easier to deploy, and only one vector instance is running per host. But the sidecar has deeper integration with the product container and can read log files, something that we decided we need.

**Topology** - Vector offers multiple https://vector.dev/docs/setup/deployment/topologies/[topologies] and already lists pros and cons. An aggregator makes it easier to configure a sink: only one place to configure it (the aggregator has "multi-host context" as Vector calls it). It also reduces requests made to the sink, as it aggregates and buffers requests.

=== Log Sink: OpenSearch

https://opensearch.org/[OpenSearch] has been picked as the sink for all the aggregated logs. No other opens have been considered, but as the sink sits at the very top of the chain, it is easy to swap it out for a different software.

We want to make it easy for users to deploy OpenSearch, but also easy to switch out the sink.

(How and where is this configured, and how can we make it easy for the user?)

=== Logging configuration

**Log levels** - It is common to have four or five log levels: Error, Warning, Info, Debug and - optionally - Trace. We want to support them across all products. The **default log level** should be Info.

**stdout vs. file** - We want to have different log levels (and possibly other settings) for stdout and file output. This makes debugging easier, without also filling up the log aggregator with very chatty logs.

**Settings per logger** - Most products (especially Java based ones) support setting a log level per package. We also want to support this in our CRD.

```
logging:
  file:
    loggers:
      ROOT:
        level: INFO
      some.interesting.module:
        level: DEBUG
  stdout:
    loggers:
      ROOT:
        level: DEBUG
      my.specific.package:
        level: TRACE
      my.other.package:
        level: TRACE
```

**Settings per role** - All of these should be configurable per role and role group. Some sub-loggers are only available in certain roles.

```
spec:
  someRole:
    config:
      logging:
        ...
    roleGroups:
      default:
        logging:
          ...
      aDifferentGroup:
        logging:
          ...
```

**Override everything** - The customer should be able to supply their own configuration file. Where this is placed depends on the product.

```
logging:
  custom:
    configMap: nameOfMyConfigMapWithTheConfigFile
```

Setting the `custom` field will disable any configurations made in `file` and `stdout`.

**Disable vector** - Vector should be optional, if the user wants to use their own logging system.

```
logging:
  enableVectorAgent: false  # defaults to true
```

=== Deploying the Stack

The operator deploys the Vector agent as a sidecar and deploys the logging configuration for the product.

The aggregator and OpenSearch sink are deployed with Helm for now, with a plan to integrate this into stackablectl. _Maybe_ we build our own operators for Vector and OpenSearch in the future.

== Consequences


=== Positive

Logs across the platform (from products and operators) are **persisted** and **aggregated** in a central location. Crashed pods can be investigated, as well as issues involving multiple products.

=== Negative

* Every pod will contain a vector sidecar container, which adds overhead.
* The unified logging configuration hides product specific logging settings.

Changing a log level might lead to a pod getting restarted.


== Links

* https://vector.dev/[Vector]
* https://vector.dev/docs/setup/deployment/roles/[Vector Deployment Roles]
* https://vector.dev/docs/setup/deployment/topologies/[Vector Deployment Topologies]
