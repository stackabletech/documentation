= Logging and Log Aggregation Architecture
Felix Hennig <felix.hennig@stackable.tech>
v0.1, 2022-10-26
:status: [draft]

* Status: {status}
* Deciders: Stackable Team
* Date: 2022-10-26

Technical Story: https://github.com/stackabletech/issues/issues/202, https://github.com/stackabletech/issues/issues/261

== Context and Problem Statement

// Describe the context and problem statement, e.g., in free form using two to three sentences. You may want to articulate the problem in form of a question.

Context: As of the day of writing, every product logs in its own log format to stdout. Logs cannot be viewed centrally, log levels cannot be set for individual parts of applications or across multiple products at once.

Product logs cannot be correlated to operator logs easily, we want to have both aggregated in a central place (aggregating operator logs is in scope).

== Decision Drivers

* **identical configuration** - All product logs should be configurable in the same way, no matter their underlying logging framework (log4j, logback, Python logging, etc.).
// TODO: Open question: Which properties do we support?
* **easily configured sinks** - A log sink (i.e. elasticsearch) should only be configured in a single place for the whole platform (not in every product instance).
* **transport security** - Logs should transmitted with encryption/TLS.
* **custom overrides** - The log format, aggregator and sink should be substitutable by the user.

== Decision

=== Log Aggregation Framework: Vector

https://vector.dev/[Vector] has been picked without comparison to other existing choices. Some googling shows https://medium.com/ibm-cloud/log-collectors-performance-benchmarking-8c5218a08fea[Vector has better performance than fluentd], the biggest name in this space. Vector is also open source and written in Rust: https://github.com/vectordotdev/vector[GitHub].

=== Log Retrieval Strategy

* Parse logs as they are (in plaintext) vs. provide custom structured logs (i.e. json/XML)
* Retrieve logs from stdout vs. from file

* Logs on stdout are still useful, because you can read them with kubectl or k9s to debug things. In that case, they should be plain, so they are easy to read for a human.
* Logs parsed by the aggregator are differt.
  * Parsing plaintext logs can be tricky, because regexes are needed
  * Using structured logs is much more robust.
* Some products _need_ to log to file, because of _reasons_. They either cannot be configured differently (which ones?), have logs confidential logs that shouldn't go do stdout, or ...
* File logs can be structured, as they are not meant to be read by a human.

=== Log Aggregation Architecture

* Agent: DaemonSet vs. Sidecar
* Aggregator vs. no aggregator

Vector offers multiple https://vector.dev/docs/setup/deployment/topologies/[topologies] and already lists pros and cons.

An aggregator makes it easier to configure a sink: only one place to configure it (the aggregator has "multi-host context" as Vector calls it).


Vector offers multiple https://vector.dev/docs/setup/deployment/roles/#agent[roles] in which it can run.

The DaemonSet is easier to deploy, and only one vector instance is running per host. But the sidecar has deeper integration with the product container and can read log files, something that we decided we need.

=== Log Sink: OpenSearch

https://opensearch.org/[OpenSearch] has been picked as the sink for all the aggregated logs. No other opens have been considered, but as the sink sits at the very top of the chain, it is easy to swap it out for a different software.

We want to make it easy for users to deploy OpenSearch, but also easy to switch out the sink.

(How and where is this configured, and how can we make it easy for the user?)

=== Logging configuration

TODO

Configuration requirements

* stdout and files should have different log levels
* different packages/components should have different log levels


at cluster level or at role level?
-> probably per role / role group

```
spec:
  someRole:
    resources:
      ...
    logging:
      stdout:
        level: DEBUG
        modules:
          my.specific.package: TRACE
          my.other.package: TRACE
      file:
        level: INFO
```


=== Deploying the Stack

Our Oper

== Decision Outcome - Summary

We have already decided to use https://vector.dev/[Vector] as an aggregator. It looked good, no other options were evaluated.

We chose to provide **plaintext logs on stdout** and **structured logs on file**. For the architecture, we chose to deploy the agent as a **sidecar** and **use an aggregator**. We chose to provide **OpenSearch** as a default Sink for logs.

== Consequences

=== Positive

* All logs can be accessed from a central placed, and logs for multiple products and operators can be correlated easily

=== Negative

* Sidecar deployment has more overhead than the DaemonSet deployment


== Links

* https://vector.dev/[Vector]
* https://vector.dev/docs/setup/deployment/roles/[Vector Deployment Roles]
* https://vector.dev/docs/setup/deployment/topologies/[Vector Deployment Topologies]

== Open Questions

* What should be the default level? WARN? INFO?
* What if we change log levels while the pod is running?