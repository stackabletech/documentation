= [short title of solved problem and solution]
Doc Writer <doc.writer@asciidoctor.org>
v0.1, YYYY-MM-DD
:status: draft

* Status: {draft}
* Deciders: [list everyone involved in the decision] <!-- optional -->
* Date: [YYYY-MM-DD when the decision was last updated] <!-- optional -->

Technical Story: https://github.com/stackabletech/hive-operator/issues/148

== Context and Problem Statement

Many products supported by the Stackable Data Platform require databases to store metadata. Currently there is no uniform, consistent way to define database conections. In addition, some Stackable operators define database credentials to be provided inline and in plain text in the cluster definitions.

A quick analysis of the status-quo regarding database connection definitions shows how different operators handle them:

* Apache Hive: the cluster custom resource defined a field called "database" with access credentials in clear text.
* Apache Airflow and Apache Superset: uses a field called "credentialSecret" that contains multiple different database connection definitions. Even worse, it contains credentials not related to a database, such as a secret to encrypt the cookies. In case of Airflow, this secret only supports the Celery executor.
* Apache Druid: uses a field called "metadataStorageDatabase" where access crdentials are expected to be inline and in plain text.

== Decision Drivers

Here we attempt to standardize the way database connections are defined across the Stackable platform in such a way that:

* Different database systems are supported.
* Access credentials are defined in Kubernetes `Secret`` objects.
* Database connections can be reused across product services and even product installations.

== Considered Options

1. A generic resource definition.
2. Database driver specific resource definition.

=== A generic resource definition

To achieve the acceptance criteria defined above, we propose a new Kubernetes resource called `DatabaseConnection` with the following fields:

[cols="1,1"]
|===
|Field name | Description
|credentials
|A string with name of a `Secret` containing at least a user name and a password field. Additional fields are allowed.
|driver
|A string with the database driver named. This is a generic field that identifies the type of the database used.
|protocol
|The protocol prefix of the final connection string. Most Java based products will use `jdbc:`.
|host
|A string with the host name to connect to.
|instance
|A string with the database instance to connect to. Optional.
|port
|A positive integer with the TCP port used for the connection. Optional.
|properties
|A dictionary of addtional properties for driver tuning like number of client threads, various buffer sizes and so on. Some drivers, like `derby` use this to define the database name and whether the DB should by automatically created or not. Optional
|===
 
The `Secret` object referenced by `credentials` must contain two fields named `USER_NAME` and `PASSWORD` but can contain additional fields like first name, last name, email, user role and so on.

=== Examples

These examples showcase the spec change required from the current status:

The current Druid metadata database connection

[source,yaml]
---
metadataStorageDatabase:
    dbType: postgresql
    connString: jdbc:postgresql://druid-postgresql/druid
    host: druid-postgresql
    port: 5432
    user: druid
    password: druid

becomes

[source,yaml]
---
metadataStorageDatabase: druid-metadata-connection
 
where `druid-metadata-connection` is a standalone `DatabaseConnection` resource defined as follows

[source,yaml]
---
apiVersion: db.stackable.tech/v1alpha1
kind: DatabaseConnection
metadata:
    name: druid-metadata-connection
spec:
    driver: postgresql
    host: druid-postgresql
    port: 5432
    protocol: jdbc:postgresql
    instance: druid
    credentials: druid-metadata-credentials

and the credentials field contains the name of a Kubernetes `Secret` defined as:

[source,yaml]
---
apiVersion: v1
kind: Secret
metadata:
  name: druid-metadata-credentials
type: Opaque
data:
  USER_NAME: druid
  PASSWORD: druid

=== Database driver specific resource definition

An alternative aproach could look like the following. We will discuss this approach on Wednesday, 07.12.2022

[source,yaml]
---
apiVersion: databaseconnection.stackable.tech/v1alpha1
kind: DatabaseConnection
metadata:
    name: druid-metadata-connection
    namespace: default
spec:
  database:
    postgresql:
      host: druid-postgresql # mandatory
      port: 5432 # defaults to some port number - depending on wether tls is enabled
      schema: druid # defaults to druid
      credentials: druid-postgresql-credentials # mandatory. key username and password
      parameters: {} # optional
    redis:
      host: airflow-redis-master # mandatory
      port: 6379 # defaults to some port number - depending on wether tls is enabled
      schema: druid # defaults to druid
      credentials: airflow-redis-credentials # optional. key password
      parameters: {} # optional
    derby:
      location: /tmp/derby/ # optional, defaults to /tmp/derby-{metadata.name}/derby.db
      parameters: # optional
        create: "true"
    genericConnectionString:
      driver: postgresql
      format: postgresql://$SUPERSET_DB_USER:$SUPERSET_DB_PASS@postgres.default.svc.local:$SUPERSET_DB_PORT/superset&param1=value1&param2=value2
      secret: ... # optional
         SUPERSET_DB_USER: ...
         SUPERSET_DB_PASS: ...
         SUPERSET_DB_PORT: ...
    generic:
      driver: postgresql
      host: superset-postgresql.default.svc.cluster.local # optional
      port: 5432 # optional
      protocol: pgsql123 # optional
      instance: superset # optional
      credentials: name-of-secret-with-credentials #optional
      parameters: {...} # optional
      connectionStringFormat: "{protocol}://{credentials.user_name}:{credentials.credentials}@{host}:{port}/{instance}&[parameters,;]"
      tls: # optional
        verification:
          ca_cert:
            ...


Hive

[source,xml]
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:postgresql://mypostgresql.testabcd1111.us-west-2.rds.amazonaws.com:5432/mypgdb</value>
    <description>PostgreSQL JDBC driver connection URL</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.postgresql.Driver</value>
    <description>PostgreSQL metastore driver class name</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>database_username</value>
    <description>the username for the DB instance</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>database_password</value>
    <description>the password for the DB instance</description>
  </property>

Druid

[source]
druid.extensions.loadList=["postgresql-metadata-storage"]
druid.metadata.storage.type=postgresql
druid.metadata.storage.connector.connectURI=jdbc:postgresql://<host>/druid
druid.metadata.storage.connector.user=druid
druid.metadata.storage.connector.password=diurd

Superset

[source]
postgresql://{username}:{password}@{host}:{port}/{database}?sslmode=require


Airflow

[source,yaml]
---
apiVersion: v1
kind: Secret
metadata:
  name: simple-airflow-credentials
type: Opaque
stringData:
  adminUser.username: airflow
  adminUser.firstname: Airflow
  adminUser.lastname: Admin
  adminUser.email: airflow@airflow.com
  adminUser.password: airflow
  connections.secretKey: thisISaSECRET_1234
  connections.sqlalchemyDatabaseUri: postgresql+psycopg2://airflow:airflow@airflow-postgresql.default.svc.cluster.local/airflow
  connections.celeryResultBackend: db+postgresql://airflow:airflow@airflow-postgresql.default.svc.cluster.local/airflow
  connections.celeryBrokerUrl: redis://:redis@airflow-redis-master:6379/0

[source,yaml]
----
Within operator-rs we have a commons struct for every DB that we support:
1. postgresql
2. mysql
3. mariadb
4. oracle
5. sqlite
6. derby
7. redis
8. etc...

This has the advantage that all our products configure e.g. a PostgresQL the exact same way.
We can also add some functions on the structs for e.g. jdbc-based connections strings or similar.

Every product operators has a enum containing all the structs of the DBs the product supports (or only a subset if Stackable does only support a subset)
This has the advantage that the CRD as well as automatically generated documentation will list not only the supported dbs, but also documents all the attributes of them.

Also every operator has a *individual* `generic` struct, which exposes exactly the settings the product has.
This enables full flexibility, as all the settings of the product are configurable.

---
kind: DruidCluster
spec:
  metadataDB:
    postgresql:
      host: postgresql # mandatory
      port: 5432 # defaults to some port number - depending on wether tls is enabled
      schema: druid # mandatory
      credentials: postgresql-credentials # mandatory. key username and password
      parameters: {} # optional
    mysql:
      host: mysql # mandatory
      port: XXXX # defaults to some port number - depending on wether tls is enabled
      schema: druid # mandatory
      credentials: mysql-credentials # mandatory. key username and password
      parameters: {} # optional
    derby:
      location: /tmp/derby/ # optional, defaults to /tmp/derby-<some-suffix>/derby.db
    generic:
      driver: postgresql # mandatory
      uri: jdbc:postgresql://<host>/druid?foo;bar # mandatory
      credentialsSecret: my-secret # mandatory. key username + password
# druid.metadata.storage.type=postgresql
# druid.metadata.storage.connector.connectURI=jdbc:postgresql://<host>/druid
# druid.metadata.storage.connector.user=druid
# druid.metadata.storage.connector.password=diurd

---
kind: SupersetCluster
spec:
  metadataDB:
    postgresql:
      host: postgresql # mandatory
      port: 5432 # defaults to some port number - depending on wether tls is enabled
      schema: superset # mandatory
      credentials: postgresql-credentials # mandatory. key username and password
      parameters: {} # optional
    mysql:
      host: mysql # mandatory
      port: XXXX # defaults to some port number - depending on wether tls is enabled
      schema: superset # mandatory
      credentials: mysql-credentials # mandatory. key username and password
      parameters: {} # optional
    sqlite:
      location: /tmp/sqlite/ # optional, defaults to /tmp/sqlite-<some-suffix>/derby.db
    generic:
      uriSecret: my-secret # mandatory. key uri
      # ALTERNATIVE SOLUTION
      uriTemplate: postgresql://$SUPERSET_DB_USER:$SUPERSET_DB_PASS@postgres.default.svc.local:$SUPERSET_DB_PORT/superset&param1=value1&param2=value2
      templateSecret: my-secret # optional
         SUPERSET_DB_USER: ...
         SUPERSET_DB_PASS: ...
         SUPERSET_DB_PORT: ...
# postgresql://{username}:{password}@{host}:{port}/{database}?sslmode=require

kind: HiveCluster
spec:
  metadataDB:
    postgresql:
      host: postgresql # mandatory
      port: 5432 # defaults to some port number - depending on wether tls is enabled
      schema: druid # mandatory
      credentials: postgresql-credentials # mandatory. key username and password
      parameters: {} # optional
    derby:
      location: /tmp/derby/ # optional, defaults to /tmp/derby-<some-suffix>/derby.db
    # Missing: MS-SQL server, Oracle
    generic:
      driver: org.postgresql.Driver # mandatory
      uri: jdbc:postgresql://postgresql.us-west-2.rds.amazonaws.com:5432/mypgdb # mandatory
      credentialsSecret: my-secret # mandatory (?). key username + password
  # <property>
  #   <name>javax.jdo.option.ConnectionURL</name>
  #   <value>jdbc:postgresql://postgresql.us-west-2.rds.amazonaws.com:5432/mypgdb</value>
  #   <description>PostgreSQL JDBC driver connection URL</description>
  # </property>
  # <property>
  #   <name>javax.jdo.option.ConnectionDriverName</name>
  #   <value>org.postgresql.Driver</value>
  #   <description>PostgreSQL metastore driver class name</description>
  # </property>
  # <property>
  #   <name>javax.jdo.option.ConnectionUserName</name>
  #   <value>database_username</value>
  #   <description>the username for the DB instance</description>
  # </property>
  # <property>
  #   <name>javax.jdo.option.ConnectionPassword</name>
  #   <value>database_password</value>
  #   <description>the password for the DB instance</description>
  # </property>
----

== Decision Outcome
