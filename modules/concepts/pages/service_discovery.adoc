= Service discovery

Most products on the Stackable platform and also in general require other software to run or to be made useful -- i.e. an analytics tool will delegate the storing of data to other applications and instead interface with various data storage solutions. The Stackable platform uses _service discovery_ to enable users and operators to easily connect different products together. There are three types of uses for the service discovery mechanism:

* A Stackable operated product instance requires a connection to another product to run. For example: NiFi requires a ZooKeeper to run.
* You want to connect non-Stackable operated software to a Stackable operated product instance. For example: You wrote your own analytics tool and want to read data from Trino.
* You want to offer a product instance not operated with a Stackable operator as a dependency to Stackable operated product instances. For example: You already run a Druid cluster and want to connect it to a Superset instance operated with a Stackable operator.

This page explains the general mechanism of service discovery and then how this mechanism works in the contexts described above.

== The service discovery ConfigMap

In the Stackable platform, every product instance is defined by a resource with a name. The operator reads the resource and creates the necessary pods and services to get the instance running. The operator is aware of the interfaces and connections that may be consumed by other products and it also knows all the details of the actual running processes.

The operator creates a ConfigMap with the same name as the product instance, in the same namespace. Inside of the ConfigMap is information about how to connect to the product instance. For example for a ZooKeeper cluster named simple-zk the Stackable ZooKeeper operator creates a ConfigMap similar to this:

[source,yaml]
----
apiVersion: v1
metadata:
  name: simple-zk
data:
  ZOOKEEPER: simple-zk-server-default-0.simple-zk-server-default.default.svc.cluster.local:2181,simple-zk-server-default-1.simple-zk-server-default.default.svc.cluster.local:2181
----

Other products can now be configured to connect to the simple-zk ZooKeeper cluster. Just by name the connection information can be looked up.

You can also use this ConfigMap in third-party or your own software to connect to product instances operated by Stackable operators. You can also create a discovery ConfigMap yourself for products that you are already operating. For example if you were already operating a ZooKeeper cluster you could create the ConfigMap for it yourself, give it a name and other Stackable operated tools with a ZooKeeper dependency are able to connect to your ZooKeeper instance.

=== Architecture

// TODO redo this and integrate it into the section above

The Operator that provides service discovery writes a `ConfigMap` with all necessary information about its exposed services. Each service has its own entry in the `ConfigMap` as can be seen with the `ZOOKEEPER` entry below:

image::service_discovery_arch.png[Service Discovery]

== Example

// TODO I would remove this here and put it into the Kafka operator instead maybe?

As a real world example, the Stackable Operator for Apache Kafka has to configure Kafka brokers with an Apache ZooKeeper connection string in order to store and share information about e.g. Kafka topics. This connection string is provided by the Stackable Operator for Apache ZooKeeper, which is aware of all the pods and services related to ZooKeeper.

Using service discovery to configure a Kafka  with an existing Zookeeper cluster requires the following steps:

1. You set up a Zookeeper cluster and a ZNode.
2. The Zookeeper operator generates the service discovery ConfigMap.
3. You set up a Kafka cluster that references the ConfigMap generated in the step above,

The following snippets highlight the relevant sections in the resource definitions .

1. First you define a ZooKeeper cluster:

[source,yaml]
----
apiVersion: zookeeper.stackable.tech/v1alpha1
kind: ZookeeperCluster
metadata:
  name: simple-zk
spec:
  servers:
    ...
----

The ZooKeeper operator creates a discovery ConfigMap with the same name as the ZooKeeper cluster, containing the connection information:

[source,yaml]
----
apiVersion: v1
metadata:
  name: simple-zk
data:
  ZOOKEEPER: simple-zk-server-default-0.simple-zk-server-default.default.svc.cluster.local:2181,simple-zk-server-default-1.simple-zk-server-default.default.svc.cluster.local:2181
----

When the Apache Zookeeper cluster is up and running, you create a xref:zookeeper::znodes.adoc[ZNode] for Kafka:

[source,yaml]
----
apiVersion: zookeeper.stackable.tech/v1alpha1
kind: ZookeeperZnode
metadata:
  name: simple-kafka-znode
spec:
  clusterRef:
    name: simple-zk
----

Finally you create a  KafkaCluster that references the ZNode object created above:

[source,yaml]
----
apiVersion: kafka.stackable.tech/v1alpha1
kind: KafkaCluster
metadata:
  name: simple-kafka
spec:
  zookeeperConfigMapName: simple-kafka-znode
  brokers:
    ...
----

The Kafka operator reads the referenced ZNode resource and looks up the ZooKeeper cluster discovery ConfigMap from which it reads the `ZOOKEEPER` field to pass the content to the Kafka instance so Kafka can connect to the ZooKeeper instance.

== More examples of connection strings

* JDBC SQL connection strings: `jdbc:postgresql://localhost:12345`
* thrift protocol: `thrift://localhost:12345`
* spark protocol: `spark://master:7077`
* REST API: `http://localhost:8080`
* HDFS: `hdfs://localhost:12345`
* ZooKeeper ZNode: `host1:2181,host2:2181/my-chroot`
