= Service discovery

Several products deployed by the Stackable platform depend on other (Stackable) products. This could be a product that requires an external database, high availability support or synchronization.

In order to programmatically resolve this dependency, the Stackable platform uses _service discovery_. A Stackable operator is aware of interfaces and connections that have to be exposed and may be consumed by other operators to configure their products. These interfaces or connections are usually referred to as _connection string_. The operator publishes these connection strings in a ConfigMap to be mounted by other products.

== Architecture

The Operator that provides service discovery writes a `ConfigMap` with all necessary information about its exposed services. Each service has its own entry in the `ConfigMap` as can be seen with the `ZOOKEEPER` entry below:

image::service_discovery_arch.png[Service Discovery]

== Example

As a real world example, the Stackable Operator for Apache Kafka has to configure Kafka brokers with an Apache ZooKeeper connection string in order to store and share information about e.g. Kafka topics. This connection string is provided by the Stackable Operator for Apache ZooKeeper, which is aware of all the pods and services related to ZooKeeper.

Using service discovery to configure a Kafka  with an existing Zookeeper cluster requires the following steps:
1. You set up a Zookeeper cluster and a ZNode.
2. The Zookeeper operator generates the service discovery ConfigMap.
3. You set up a Kafka cluster that references the ConfigMap generated in the step above,

The following snippets highlight the relevant sections in the resource definitions .

1. First you define a ZooKeeper cluster:

[source,yaml]
----
apiVersion: zookeeper.stackable.tech/v1alpha1
kind: ZookeeperCluster
metadata:
  name: simple-zk
spec:
  servers:
    ...
----

The ZooKeeper operator creates a discovery ConfigMap with the same name as the ZooKeeper cluster, containing the connection information:

[source,yaml]
----
apiVersion: v1
metadata:
  name: simple-zk
data:
  ZOOKEEPER: simple-zk-server-default-0.simple-zk-server-default.default.svc.cluster.local:2181,simple-zk-server-default-1.simple-zk-server-default.default.svc.cluster.local:2181
----

When the Apache Zookeeper cluster is up and running, you create a xref:zookeeper::znodes.adoc[ZNode] for Kafka:

[source,yaml]
----
apiVersion: zookeeper.stackable.tech/v1alpha1
kind: ZookeeperZnode
metadata:
  name: simple-kafka-znode
spec:
  clusterRef:
    name: simple-zk
----

Finally you create a  KafkaCluster that references the ZNode object created above:

[source,yaml]
----
apiVersion: kafka.stackable.tech/v1alpha1
kind: KafkaCluster
metadata:
  name: simple-kafka
spec:
  zookeeperConfigMapName: simple-kafka-znode
  brokers:
    ...
----

The Kafka operator reads the referenced ZNode resource and looks up the ZooKeeper cluster discovery ConfigMap from which it reads the `ZOOKEEPER` field to pass the content to the Kafka instance so Kafka can connect to the ZooKeeper instance.

== More examples of connection strings

* JDBC SQL connection strings: `jdbc:postgresql://localhost:12345`
* thrift protocol: `thrift://localhost:12345`
* spark protocol: `spark://master:7077`
* REST API: `http://localhost:8080`
* HDFS: `hdfs://localhost:12345`
* ZooKeeper ZNode: `host1:2181,host2:2181/my-chroot`
