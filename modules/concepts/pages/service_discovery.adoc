= Service discovery

Products on the Stackable platform can, and in some cases must be connected with each other to run correctly. Some products are fundamental to the platform while others depend on them. For example, a NiFi cluster requires a ZooKeeper connection to run in distributed mode. Other products can optionally be connected with each other for better data flow. For example Trino does not store the query data  it's self, instead it interfaces with other applications to get access to it. The Stackable platform uses _service discovery_ to enable users and operators to easily connect different products together. There are three types of uses for the service discovery mechanism:

* A Stackable operated product instance requires a connection to another product to run. For example: NiFi requires a ZooKeeper to run.
* You want to connect non-Stackable operated software to a Stackable operated product instance. For example: You wrote your own analytics tool and want to read data from Trino.
* You want to offer a product instance not operated with a Stackable operator as a dependency to Stackable operated product instances. For example: You already run a Druid cluster and want to connect it to a Superset instance operated with a Stackable operator.

This page explains the general mechanism of service discovery and how this mechanism works in the contexts described above.

== The service discovery ConfigMap

In the Stackable platform, every product instance is defined by a resource with a name, for example a ZooKeeperCluster:

[source,yaml]
----
apiVersion: zookeeper.stackable.tech/v1alpha1
kind: ZookeeperCluster
metadata:
  name: simple-zk
spec:
  ...
----

The Zookeeper operator reads the resource and creates the necessary pods and services to get the instance running. It is aware of the interfaces and connections that may be consumed by other products and it also knows all the details of the actual running processes.

The operator creates a ConfigMap with the same name as the product instance, in the same namespace. Inside of the ConfigMap is information about how to connect to the product instance. For example for a ZooKeeper cluster named simple-zk the Stackable ZooKeeper operator creates a ConfigMap similar to this:

[source,yaml]
----
apiVersion: v1
metadata:
  name: simple-zk
data:
  ZOOKEEPER: simple-zk-server-default-0.simple-zk-server-default.default.svc.cluster.local:2181,simple-zk-server-default-1.simple-zk-server-default.default.svc.cluster.local:2181
----

The information needed to connect can be a string like above, for example a JDBC connect string: `jdbc:postgresql://localhost:12345`. But a ConfigMap can also contain whole configuration files which can then be mounted into a Pod. This is the case for xref:hdfs::discovery.adoc[HDFS], where the `core-site.xml` and `hdfs-site.xml` files are put into the discovery ConfigMap.

*The ConfigMap always has the same name as cluster resource.* Which allows Stackable operators as well as users to look up service connection information simply by the name of the product instance they want to connect to.

== Usage of the service discovery ConfigMap

Above three use cases for service discovery ConfigMap were outlined. They are described in more detail below.

=== Stackable internal usage

Stackable operators use the discovery ConfigMap to automatically connect to service dependencies. Hbase requires HDFS to run. With an HdfsCluster defined as such:

[source,yaml]
----
apiVersion: hdfs.stackable.tech/v1alpha1
kind: HdfsCluster
metadata:
  name: simple-hdfs
spec:
  ...
----
The HDFS instance is referenced in HBase like this:

[source,yaml]
----
apiVersion: hbase.stackable.tech/v1alpha1
kind: HbaseCluster
metadata:
  name: simple-hbase
spec:
  hdfsConfigMapName: simple-hdfs
  ...
----

With the HdfsCluster name simple-hdfs, the HBase Operator looks up the discovery ConfigMap for the simple-hdfs HdfsCluster, retrieves the information it needs to configure Hbase and configures the simple-hbase instance.

=== Connect third-party products

You can connect your own products to Stackable-operated product instances. Just use the name of the instance to retrieve the ConfigMap and use the information in there to connect your own service. You can find links to these documentation pages below in the <<whats-next>> section.

=== Provide custom dependencies

It is not uncommon to already have some core software running in your stack, such as HDFS. Looking at xref:hdfs::discovery.adoc[the discovery documentation for HDFS], you can see that the discovery ConfigMap for HDFS contains the `core-site.xml` and `hdfs-site-xml` files.

If you are already operating an HDFS instance, you can simply provide a ConfigMap containing these files. You can then use the name of this ConfigMap in the configuration of other products, such as HBase.

[#whats-next]
== What's next

Consult discovery ConfigMap documentation for specific products:

* xref:hdfs::discovery.adoc[Apache Hadoop HDFS]
* xref:hive::discovery.adoc[Apache Hive]
* xref:kafka::discovery.adoc[Apache Kafka]
* xref:opa::discovery.adoc[OPA]
* xref:zookeeper::discovery.adoc[Apache ZooKeeper]
